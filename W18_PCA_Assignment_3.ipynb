{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach?\n",
        "Explain with an example."
      ],
      "metadata": {
        "id": "oW3dTvB5xpGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eigenvalues and eigenvectors are fundamental concepts in linear algebra. They are used to understand the behavior of linear transformations.\n",
        "\n",
        "- Eigenvector: An eigenvector of a square matrix A is a non-zero vector v such that when multiplied by A, it results in a scalar multiple of itself.         \n",
        "Mathematically: Av = λv\n",
        "- Eigenvalue: The scalar λ in the equation above is the corresponding eigenvalue. It represents the factor by which the eigenvector is scaled when multiplied by the matrix A."
      ],
      "metadata": {
        "id": "pVV2icnCxpCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is eigen decomposition and what is its significance in linear algebra?"
      ],
      "metadata": {
        "id": "9NRHGRoyxpAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eigen decomposition is a matrix factorization technique that decomposes a square matrix A into the product of three matrices.\n",
        "\n",
        "**Significance of Eigen Decomposition:**\n",
        "- Diagonalization: It simplifies matrix operations, especially when dealing with powers of matrices or solving systems of differential equations.\n",
        "- Principal Component Analysis (PCA): It's a fundamental tool in PCA, used to reduce dimensionality and extract important features from data."
      ],
      "metadata": {
        "id": "FxbCtI8lxo8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the\n",
        "Eigen-Decomposition approach? Provide a brief proof to support your answer."
      ],
      "metadata": {
        "id": "uFMDZMPFxo64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A square matrix A is diagonalizable if and only if it has n linearly independent eigenvectors, where n is the size of the matrix. This means that we can find a matrix P whose columns are these eigenvectors such that:\n",
        "\n",
        "A = PDP^(-1)    \n",
        "where D is a diagonal matrix with the eigenvalues of A on its diagonal."
      ],
      "metadata": {
        "id": "vCgpolHaxo28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach?\n",
        "How is it related to the diagonalizability of a matrix? Explain with an example."
      ],
      "metadata": {
        "id": "RBwg5ccbxo1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Spectral Theorem states that a symmetric matrix is always diagonalizable. Moreover, its eigenvalues are real numbers, and its eigenvectors are orthogonal.      \n",
        "\n",
        "This theorem is significant because it provides a powerful tool for analyzing symmetric matrices. It allows us to decompose a symmetric matrix into a product of a matrix of eigenvectors and a diagonal matrix of eigenvalues. This decomposition can be used to solve various problems in linear algebra, including solving systems of linear equations, finding the eigenvalues and eigenvectors of a matrix, and analyzing the behavior of dynamical systems."
      ],
      "metadata": {
        "id": "-rr20K_5xoxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. How do you find the eigenvalues of a matrix and what do they represent?\n"
      ],
      "metadata": {
        "id": "yZUWkMQ9xovu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Eigenvalues:\n",
        "**1. Characteristic Polynomial:**\n",
        "- Subtract λ (a scalar) from the diagonal elements of the matrix A.\n",
        "- Calculate the determinant of this new matrix (A - λI), where I is the identity matrix.\n",
        "- Set the determinant equal to zero and solve for λ.\n",
        "\n",
        "**2. Solving the Characteristic Equation:**   \n",
        "- The solutions to the characteristic equation are the eigenvalues of the matrix A.\n",
        "\n",
        "**Representation of Eigenvalues:**\n",
        "- Eigenvalues represent the scaling factors of the eigenvectors when the matrix A is applied to them.\n",
        "- They provide information about the behavior of the linear transformation associated with the matrix.\n"
      ],
      "metadata": {
        "id": "ynMVgejNxoqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What are eigenvectors and how are they related to eigenvalues?\n"
      ],
      "metadata": {
        "id": "Nh0yxrW8xonC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eigenvectors:** Eigenvectors are non-zero vectors that, when multiplied by a matrix A, are scaled by a scalar factor λ (the eigenvalue).   \n",
        "\n",
        "**Relation to Eigenvalues:**\n",
        "- For a given eigenvalue λ, the corresponding eigenvector v satisfies the equation:    \n",
        "Av = λv    \n",
        "- This equation implies that when the matrix A is applied to the eigenvector v, the result is the same as scaling v by the eigenvalue λ."
      ],
      "metadata": {
        "id": "yYLEPR0TxolP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?"
      ],
      "metadata": {
        "id": "NT5qehvixohs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eigenvectors:**\n",
        "- Eigenvectors represent the directions in which the linear transformation defined by the matrix A acts by simple scaling.\n",
        "- They are the special vectors that are not rotated, only scaled, when the matrix A is applied to them.   \n",
        "\n",
        "**Eigenvalues:**\n",
        "- Eigenvalues determine the amount of scaling along the direction of the corresponding eigenvector.\n",
        "- Positive eigenvalues correspond to stretching, negative eigenvalues to reflection and stretching, and zero eigenvalues to collapse."
      ],
      "metadata": {
        "id": "jDztkBh4xofx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What are some real-world applications of eigen decomposition?\n"
      ],
      "metadata": {
        "id": "BLalS1qD0cLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eigen decomposition is a fundamental tool in linear algebra with numerous applications in various fields. Here are a few examples:\n",
        "- Used in data science and machine learning to reduce dimensionality of data.\n",
        "- Eigenvectors corresponding to the largest eigenvalues capture the most variance in the data."
      ],
      "metadata": {
        "id": "09Ih_YR00b5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. Can a matrix have more than one set of eigenvectors and eigenvalues?"
      ],
      "metadata": {
        "id": "rHtwik2a0b2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, a matrix has a unique set of eigenvalues. However, a given eigenvalue can have multiple linearly independent eigenvectors associated with it. These eigenvectors form the eigenspace corresponding to that eigenvalue."
      ],
      "metadata": {
        "id": "1R4cUP0o0byb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning?\n",
        "Discuss at least three specific applications or techniques that rely on Eigen-Decomposition."
      ],
      "metadata": {
        "id": "aGBbOmtq0bv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eigen-decomposition is a powerful tool that has significant applications in data analysis and machine learning. Here are three specific applications:   \n",
        "\n",
        "- PCA is a dimensionality reduction technique that identifies the directions of maximum variance in a dataset.  \n",
        "- Eigenvectors of the covariance matrix correspond to the principal components, which are orthogonal directions that capture the most variance.\n",
        "- By selecting a subset of these principal components, we can reduce the dimensionality of the data while preserving most of the information.\n",
        "\n",
        "In addition to these specific applications, eigen-decomposition is also used in various other machine learning techniques, such as:\n",
        "\n",
        "- Feature extraction: Extracting relevant features from high-dimensional data.\n",
        "- Clustering: Grouping similar data points together."
      ],
      "metadata": {
        "id": "9n_8qY2y02fk"
      }
    }
  ]
}