{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the KNN algorithm?\n"
      ],
      "metadata": {
        "id": "TNxVP7FiSTMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The K-Nearest Neighbors (KNN) algorithm is a simple, supervised machine learning method used for both classification and regression tasks. It's based on the principle of similarity or \"nearness,\" where the algorithm predicts the label or value of a new data point by considering the labels or values of its K-nearest neighbors in the training dataset."
      ],
      "metadata": {
        "id": "rMUJ7HkySTJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. How do you choose the value of K in KNN?"
      ],
      "metadata": {
        "id": "zG0wQCgKSTF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing the optimal value of K is crucial for the performance of the KNN algorithm.\n",
        "- Train the KNN model on a subset of folds(Cross-validation) and evaluate its performance on the remaining fold for different values of K.\n",
        "- Repeat this process for all folds and choose the K that gives the best average performance.\n",
        "- Define a range of possible K values.\n",
        "- Train(Grid search) and evaluate the KNN model for each K value in the range."
      ],
      "metadata": {
        "id": "Wy6Fhe3BSTDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What is the difference between KNN classifier and KNN regressor?"
      ],
      "metadata": {
        "id": "OEX2b6i8STB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN Classifier:\n",
        "Target: Categorical variables (e.g., \"spam\" or \"not spam,\" \"dog\" or \"cat\").    \n",
        "Prediction: Assigns the most frequent class among the K nearest neighbors to the new data point.     \n",
        "\n",
        "### KNN Regressor:\n",
        "Target: Continuous numerical variables (e.g., house prices, stock prices).     \n",
        "Prediction: Predicts the value for the new data point based on the average or weighted average of the values of the K nearest neighbors."
      ],
      "metadata": {
        "id": "oH6InRb3SS_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How do you measure the performance of KNN?"
      ],
      "metadata": {
        "id": "ZtpXFOiNSS9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of performance metric depends on whether you're dealing with classification or regression:   \n",
        "\n",
        "**Classification:**       \n",
        "Accuracy: Proportion of correctly classified instances.        \n",
        "Confusion matrix: Visualizes the distribution of true positives, true negatives, false positives, and false negatives.  \n",
        "\n",
        "**Regression:**         \n",
        "Mean Squared Error (MSE): Average of the squared differences between predicted and actual values.          \n",
        "R-squared: Coefficient of determination, which measures the proportion of variance explained by the model."
      ],
      "metadata": {
        "id": "dCQDT_0YSS6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is the curse of dimensionality in KNN?"
      ],
      "metadata": {
        "id": "FwDLHaiXSS3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. How do you handle missing values in KNN?"
      ],
      "metadata": {
        "id": "LVATkUumSS0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean/Median Imputation: Replace missing values with the mean or median of the corresponding feature in the entire dataset. This is a simple but potentially less accurate method, especially if the data has significant outliers.            \n",
        "Mode Imputation (for categorical variables): Replace missing values with the most frequent category.\n"
      ],
      "metadata": {
        "id": "1kR7OwBSSSvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
        "which type of problem?"
      ],
      "metadata": {
        "id": "OomyGamRUgga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN Classifier**\n",
        "- Target Variable - Categorical (e.g., \"spam\" or \"not spam\")\n",
        "- Prediction Method - Assigns the most frequent class among the K nearest neighbors.\n",
        "- Performance Metrics - Accuracy, Precision, Recall, F1-score, Confusion Matrix\n",
        "\n",
        "**KNN Regressor**\n",
        "- Target Variable - Continuous (e.g., house prices, stock prices)\n",
        "- Prediction Method - Predicts the value based on the average or weighted average of the K nearest neighbors.\n",
        "- Performance Metrics - Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), R-squared\n",
        "\n",
        "### Which one is better for which type of problem?\n",
        "**KNN Classifier:** Ideal for problems where you need to categorize data into discrete classes.     \n",
        "**KNN Regressor:** Suitable for problems where you need to predict a continuous numerical value.    \n"
      ],
      "metadata": {
        "id": "19hDWPtNUgc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
        "and how can these be addressed?"
      ],
      "metadata": {
        "id": "9mPz_xBkUgY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Strengths:\n",
        "- Easy to grasp the underlying concept and relatively straightforward to code.\n",
        "- Can be used for both classification and regression tasks.     \n",
        "- KNN is a lazy learning algorithm, which means it doesn't require a separate training phase. It stores the entire training dataset and makes predictions based on the stored data.\n",
        "- Can capture complex non-linear relationships in the data.\n",
        "\n",
        "### Weaknesses:\n",
        "- Noise in the data can significantly impact the performance, especially with low values of K.\n",
        "- Can be computationally expensive, especially with large datasets and high-dimensional data, as it requires calculating distances to all training points.\n",
        "- Performance degrades in high-dimensional spaces.\n",
        "- Selecting the optimal value of K is crucial and can significantly impact performance.\n",
        "\n",
        "### Addressing Weaknesses:\n",
        "- Use techniques like data cleaning, feature selection, or more robust distance metrics.\n",
        "- Consider techniques like k-d trees or ball trees to speed up distance calculations.\n",
        "- Employ dimensionality reduction techniques (e.g., PCA), feature selection, or distance metrics suitable for high-dimensional data.\n",
        "- Utilize cross-validation, the elbow method, or grid search to find the optimal K value.\n"
      ],
      "metadata": {
        "id": "Z0qi2q8JUgSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
      ],
      "metadata": {
        "id": "1B4ZO1L-UgOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Euclidean Distance\n",
        "Definition: The straight-line distance between two points in Euclidean space.     \n",
        "Visualization: Imagine the shortest path between two points as a straight line.\n",
        "\n",
        "### Manhattan Distance\n",
        "Definition: The sum of the absolute differences of their Cartesian coordinates.         \n",
        "Visualization: Imagine the distance as if you were navigating a city grid, only able to move along horizontal and vertical streets."
      ],
      "metadata": {
        "id": "ydfb1vyDUgLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. What is the role of feature scaling in KNN?"
      ],
      "metadata": {
        "id": "89zvrxqCVx38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature scaling is a crucial preprocessing step for KNN, especially when dealing with features that have different scales or units. Here's why:\n",
        "- Impact of Feature Scales: Distance-based algorithms like KNN are heavily influenced by the scale of features. Features with larger scales can dominate the distance calculations, overshadowing the contributions of features with smaller scales.           \n",
        "- Importance of Feature Scaling: Scaling features to a common range (e.g., between 0 and 1 or -1 and 1) ensures that all features contribute equally to the distance calculations."
      ],
      "metadata": {
        "id": "nHSmLXPBXIT4"
      }
    }
  ]
}